{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with datasets in Python\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# db connectivity\n",
    "import sqlalchemy\n",
    "\n",
    "# load osm data\n",
    "import osmnx as ox\n",
    "\n",
    "# visualization of spatial data\n",
    "from keplergl import KeplerGl\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter kepler.gl (i.e. \"all\") warnings until I know better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_host = 'xxx.xxx.xxx.xxx'\n",
    "hdb_port = xxxxx\n",
    "hdb_user = 'xxx'\n",
    "hdb_password = 'xxx'\n",
    "\n",
    "hdb_schema = 'xxx'\n",
    "\n",
    "connection_string = 'hana://%s:%s@%s:%s' % (hdb_user, hdb_password, hdb_host, hdb_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable inline SQL for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "%config SqlMagic.displaylimit = 100\n",
    "%sql $connection_string\n",
    "%sql SET SCHEMA $hdb_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the SRS that is going to be used. Choose one which is suitable for Porto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srid = 5018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to install the SRS if not done yet: https://launchpad.support.sap.com/#/notes/2810660"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %sql CREATE PREDEFINED SPATIAL REFERENCE SYSTEM IDENTIFIED BY 5018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare, Persists and Enhance Trajectory Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download CSV from https://www.kaggle.com/crailtap/taxi-trajectory and reference the respective file below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_csv = pd.read_csv('/Users/d059468/Downloads/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the data, we can see that POLYLINE is not WKT and Timestamp is in UNIX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the timestamp to proper datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv[\"TIMESTAMP\"] = pd.to_datetime(df_csv['TIMESTAMP'],unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build WKT. I am a regex and Python noob and just do it old school. I appreciate any hints for making this more elegant :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_csv[\"POLYLINE\"] = df_csv[\"POLYLINE\"].str.replace(\",\", \" \").str.replace(\"\\] \\[\", \",\").str.replace(\"\\[\\[\", \"LINESTRING(\").str.replace(\"\\]\\]\",\")\")\n",
    "df_csv[\"POLYLINE\"] = df_csv[\"POLYLINE\"].str.replace(\"\\[\\]\", \"LINESTRING EMPTY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some empty trajectories. These are not necessarily an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_csv[\"POLYLINE\"].str.contains('LINESTRING EMPTY').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is a large number of LINESTRINGS containing only one point. From a geometrical perspective this is not a valid linestring, which is why SAP HANA will not allow to create this objects with type linestring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv[\"POLYLINE\"].str.contains('LINESTRING\\(-?\\d*\\.?\\d*\\s*-?\\d*\\.?\\d*\\)').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just filter these suspicious and empty trajectories as it does not add benefit to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_csv = df_csv[~df_csv[\"POLYLINE\"].str.contains('LINESTRING EMPTY')]\n",
    "df_csv = df_csv[~df_csv[\"POLYLINE\"].str.contains('LINESTRING\\(-?\\d*\\.?\\d*\\s*-?\\d*\\.?\\d*\\)')]\n",
    "df_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data based on date. This amount of data will fit into a HANA Express instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Date range: %s - %s \" % (df_csv[\"TIMESTAMP\"].min(), df_csv[\"TIMESTAMP\"].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = df_csv[(df_csv[\"TIMESTAMP\"] >= '2013-12-01') & (df_csv[\"TIMESTAMP\"] <= '2014-02-01')]\n",
    "df_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polyline is now a proper WKT and Timestamp a readable date/time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist Trajectory Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the rest to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hdb_connection = sqlalchemy.create_engine(connection_string).connect()\n",
    "\n",
    "obj_cols = df_csv.select_dtypes(include=[object]).columns.values.tolist()\n",
    "obj_cols.remove('POLYLINE')\n",
    "df_csv.to_sql(name = 'taxi', schema=hdb_schema, con = hdb_connection, if_exists = 'replace', chunksize = 500, dtype={c: sqlalchemy.types.String(512) for c in obj_cols})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a proper spatial dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE TAXI ADD (SHAPE ST_GEOMETRY($srid))\n",
    "%sql UPDATE TAXI SET SHAPE = ST_GEOMFROMTEXT(POLYLINE, 4326).ST_TRANSFORM($srid)\n",
    "%sql ALTER TABLE TAXI DROP (POLYLINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that data has arrived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) FROM TAXI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excursus: Why not always use 3857 when going to planar projection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg travel distance with round earth SRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_result = %sql SELECT AVG(SHAPE.ST_TRANSFORM(4326).ST_LENGTH()) FROM TAXI\n",
    "# dist_4326 = float(sql_result[0][0])\n",
    "# dist_4326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg travel distance with webmercator projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_result = %sql SELECT AVG(SHAPE.ST_TRANSFORM(3857).ST_LENGTH()) FROM TAXI\n",
    "# dist_3857 = float(sql_result[0][0])\n",
    "# dist_3857"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg travel distance with projection suitable for Porto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_result = %sql SELECT AVG(SHAPE.ST_TRANSFORM(5018).ST_LENGTH()) FROM TAXI\n",
    "# dist_5018 = float(sql_result[0][0])\n",
    "# dist_5018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Deviation 3857: %f percent' % (100 * (dist_3857 / dist_4326 - 1)))\n",
    "# print('Deviation 5018: %f percent' % (100 * (dist_5018 / dist_4326 - 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhance dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add start and end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE TAXI ADD (STARTPOINT ST_GEOMETRY($srid), ENDPOINT ST_GEOMETRY($srid))\n",
    "%sql UPDATE TAXI SET STARTPOINT = SHAPE.ST_STARTPOINT(), ENDPOINT = SHAPE.ST_ENDPOINT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add trip duration in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE TAXI ADD (DURATION INTEGER)\n",
    "%sql UPDATE TAXI SET DURATION = (SHAPE.ST_NUMPOINTS() - 1) * 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add start and end time (start time just for the sake of consistent naming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE TAXI ADD (STARTTIME TIMESTAMP, ENDTIME TIMESTAMP)\n",
    "%sql UPDATE TAXI SET STARTTIME = TIMESTAMP, ENDTIME = ADD_SECONDS(TIMESTAMP, DURATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add driving distance in meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE TAXI ADD (DISTANCE INTEGER)\n",
    "%sql UPDATE TAXI SET DISTANCE = TO_INTEGER(SHAPE.ST_LENGTH())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add average speed in km/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE TAXI ADD (SPEED_AVG INTEGER)\n",
    "%sql UPDATE TAXI SET SPEED_AVG = TO_INTEGER(DISTANCE/DURATION * 3.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flag weekend days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE TAXI ADD (IS_WEEKEND INTEGER)\n",
    "%sql UPDATE TAXI SET IS_WEEKEND = CASE WHEN WEEKDAY(TIMESTAMP) >= 5 THEN 1 ELSE 0 END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flag Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE TAXI ADD (IS_HOLIDAY INTEGER)\n",
    "%sql UPDATE TAXI SET IS_HOLIDAY = CASE WHEN DAY_TYPE='B' THEN 1 ELSE 0 END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flag days before holidays or weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE TAXI ADD (IS_PARTYNIGHT INTEGER)\n",
    "%sql UPDATE TAXI SET IS_PARTYNIGHT = CASE WHEN DAY_TYPE='C' OR WEEKDAY(TIMESTAMP) = 4 THEN 1 ELSE 0 END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prep finished. Perform delta merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql MERGE DELTA OF TAXI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trips without actual trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(We actually removed those beforehand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) FROM TAXI WHERE SHAPE.ST_ISEMPTY() = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing GPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) FROM TAXI WHERE MISSING_DATA > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invalid trajectories (in terms of geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) FROM TAXI WHERE SHAPE.ST_ISVALID() = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, all of those contain only two identical points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) FROM TAXI WHERE SHAPE.ST_ISVALID() = 0 AND STARTPOINT != ENDPOINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Too) short trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) FROM TAXI WHERE DISTANCE < 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Too) fast trips "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(But what is too fast? https://www.youtube.com/watch?v=buQxF0eIeXI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) FROM TAXI WHERE SPEED_AVG > 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove inconsistent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql DELETE FROM TAXI WHERE SHAPE.ST_ISEMPTY() = 1 OR SHAPE.ST_ISVALID() = 0 OR DISTANCE < 200 OR SPEED_AVG > 150 OR MISSING_DATA > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Persist POIs for Porto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the polygon for which we would like to download POI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_result = %sql SELECT ST_CONVEXHULLAGGR(SHAPE).ST_TRANSFORM(4326).ST_ASWKT() FROM TAXI\n",
    "df_poi_shape = sql_result.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just check which area has been selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeplerGl(height=500, data={'poi_shape':df_poi_shape})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load POIs from relevant categories. (see https://wiki.openstreetmap.org/wiki/Key:amenity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# query has strong selectivity and should not be split up by area size\n",
    "ox.config(max_query_area_size = 1000000000000)\n",
    "\n",
    "gdf_poi = ox.geometries.geometries_from_polygon(\n",
    "    df_poi_shape[df_poi_shape.columns[0]].apply(wkt.loads).iloc[0],\n",
    "    tags = {\"amenity\":[\n",
    "                'taxi', 'car_rental', 'bus_station',            #transportation\n",
    "                'bar', 'restaurant', 'pub', 'cafe',             #sustenance\n",
    "                'university', 'college',                        #education\n",
    "                'clinic', 'doctors', 'hospital', 'pharmacy'     #healthcare\n",
    "                'cinema', 'nightclub', 'stripclub', 'theater',  #entertainment\n",
    "                'conference_centre'\n",
    "    ]}\n",
    ")\n",
    "gdf_poi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to dataframe and handle datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poi = pd.DataFrame(gdf_poi)\n",
    "df_poi = df_poi.reset_index()\n",
    "df_poi = df_poi[['osmid', 'geometry', 'amenity', 'name']]\n",
    "df_poi[\"geometry\"] = df_poi[\"geometry\"].astype(\"str\")\n",
    "df_poi = df_poi.infer_objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hdb_connection = sqlalchemy.create_engine(connection_string).connect()\n",
    "obj_cols = df_poi.select_dtypes(include=[object]).columns.values.tolist()\n",
    "obj_cols.remove('geometry')\n",
    "df_poi.to_sql(name = 'osm_poi', schema=hdb_schema, con = hdb_connection, if_exists = 'replace', chunksize = 100, dtype={c:sqlalchemy.types.String(512) for c in obj_cols})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ST_GEOMETRY column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE OSM_POI ADD (SHAPE ST_GEOMETRY($srid))\n",
    "%sql UPDATE OSM_POI SET SHAPE = ST_GEOMFROMTEXT(GEOMETRY, 4326).ST_TRANSFORM($srid)\n",
    "%sql ALTER TABLE OSM_POI DROP (GEOMETRY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that data has arrived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT COUNT(*) FROM OSM_POI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Reference Hexagonal Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further analysis it will be helpful to persist a hexagonal grid covering all relevant points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql DROP TABLE REFGRID\n",
    "%sql CREATE COLUMN TABLE REFGRID (HEXID VARCHAR(50), HEXCELL ST_GEOMETRY($srid), HEXCENTROID ST_GEOMETRY($srid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO REFGRID\n",
    "(\n",
    "    SELECT \n",
    "        'HEXID-'|| ST_CLUSTERID() AS HEXID,\n",
    "        ST_CLUSTERCELL() AS HEXCELL, \n",
    "        ST_CLUSTERCELL().ST_CENTROID() AS HEXCENTROID\n",
    "    FROM ((SELECT STARTPOINT AS PT FROM TAXI) UNION (SELECT ENDPOINT AS PT FROM TAXI))\n",
    "    GROUP CLUSTER BY PT USING HEXAGON X CELLS 250\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick look at the refgrid (..also including the convex hull of all points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql sql_result <<\n",
    "SELECT \n",
    "    HEXID, \n",
    "    HEXCENTROID.ST_TRANSFORM(4326).ST_ASWKT() AS HEXCENTROID,\n",
    "    HEXCELL.ST_TRANSFORM(4326).ST_ASWKT() AS HEXCELL\n",
    "FROM REFGRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refgrid = sql_result.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeplerGl(height=500, data={'refgrid':df_refgrid, 'poi_shape':df_poi_shape})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Basic Spatial Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The very basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average ride distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT AVG(DISTANCE)/1000 AS DISTANCE_KM FROM TAXI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average ride duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT AVG(DURATION)/60 AS DURATION_MINUTES FROM TAXI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT AVG(SPEED_AVG) AS SPEED_KMH FROM TAXI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize samples using kepler.gl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch some sample trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql sql_result << \n",
    "SELECT TOP 1000\n",
    "    INDEX, \n",
    "    TRIP_ID, \n",
    "    CALL_TYPE, \n",
    "    TAXI_ID, \n",
    "    STARTTIME, \n",
    "    ENDTIME,\n",
    "    SPEED_AVG,\n",
    "    SHAPE.ST_TRANSFORM(4326).ST_ASWKT() as SHAPE\n",
    "FROM TAXI\n",
    "ORDER BY RAND()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_trajectories = sql_result.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure and display map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "map_sample_config = {\n",
    "    'version': 'v1',\n",
    "    'config': {\n",
    "        'mapState': {\n",
    "            'latitude': 41.16064263660347,\n",
    "            'longitude': -8.61937846161915,\n",
    "            'zoom': 10.936755405111594\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "KeplerGl(height=500, data={'samples':df_sample_trajectories}, config=map_sample_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also get the POIs on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_result = %sql SELECT OSMID, SHAPE.ST_TRANSFORM(4326).ST_ASWKT() AS SHAPE, AMENITY, NAME FROM OSM_POI\n",
    "df_all_poi = sql_result.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeplerGl(height=500, data={'pois':df_all_poi, 'samples':df_sample_trajectories}, config=map_sample_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Pick-up Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql sql_result <<\n",
    "SELECT \n",
    "    ST_CLUSTERID(),\n",
    "    ST_CLUSTERCELL().ST_TRANSFORM(4326).ST_ASGEOJSON() AS HEXCELL,\n",
    "    LOG(10, COUNT(*)) AS QUANTITY\n",
    "FROM TAXI\n",
    "GROUP CLUSTER BY STARTPOINT USING HEXAGON X CELLS 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickup_hex = sql_result.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure map visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_pickup_hex_config = {'version': 'v1',\n",
    " 'config': {'visState': {\n",
    "   'layers': [{\n",
    "     'id': 'k6a7rbn',\n",
    "     'type': 'geojson',\n",
    "     'config': {\n",
    "      'dataId': 'hex',\n",
    "      'label': 'hex',\n",
    "      'color': [241, 92, 23],\n",
    "      'columns': {'geojson': 'hexcell'},\n",
    "      'isVisible': True,\n",
    "      'visConfig': {\n",
    "       'opacity': 0.8,\n",
    "       'thickness': 0.5,\n",
    "       'strokeColor': [34, 63, 154],\n",
    "       'colorRange': {'name': 'Uber Viz Diverging 1.5',\n",
    "        'type': 'diverging',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#00939C',\n",
    "         '#5DBABF',\n",
    "         '#BAE1E2',\n",
    "         '#F8C0AA',\n",
    "         '#DD7755',\n",
    "         '#C22E00']},\n",
    "       'strokeColorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'radius': 10,\n",
    "       'sizeRange': [0, 10],\n",
    "       'radiusRange': [0, 50],\n",
    "       'heightRange': [0, 500],\n",
    "       'elevationScale': 5,\n",
    "       'stroked': False,\n",
    "       'filled': True,\n",
    "       'enable3d': True,\n",
    "       'wireframe': False},\n",
    "      'textLabel': [{'field': None,\n",
    "        'color': [255, 255, 255],\n",
    "        'size': 18,\n",
    "        'offset': [0, 0],\n",
    "        'anchor': 'start',\n",
    "        'alignment': 'center'}]},\n",
    "     'visualChannels': {'colorField': {'name': 'quantity', 'type': 'real'},\n",
    "      'colorScale': 'quantile',\n",
    "      'sizeField': None,\n",
    "      'sizeScale': 'linear',\n",
    "      'strokeColorField': None,\n",
    "      'strokeColorScale': 'quantile',\n",
    "      'heightField': {'name': 'quantity', 'type': 'real'},\n",
    "      'heightScale': 'linear',\n",
    "      'radiusField': None,\n",
    "      'radiusScale': 'linear'}}],\n",
    "   'layerBlending': 'normal',\n",
    "   'splitMaps': [],\n",
    "   'animationConfig': {'currentTime': None, 'speed': 1}},\n",
    "  'mapState': {\n",
    "   'bearing': 115.5596330275229,\n",
    "   'dragRotate': True,\n",
    "   'latitude': 41.191169915709146,\n",
    "   'longitude': -8.631325549115484,\n",
    "   'pitch': 57.45876401383432,\n",
    "   'zoom': 11.013713014514414,\n",
    "   'isSplit': False},\n",
    "  }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KeplerGl(height=500, data={'hex':df_pickup_hex}, config=map_pickup_hex_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POIs in the Cluster Cells with Most Pick-ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql sql_result <<\n",
    "SELECT B.OSMID, B.SHAPE.ST_TRANSFORM(4326).ST_ASWKT() AS OSMSHAPE, B.AMENITY, B.NAME, A.HEXCELL.ST_TRANSFORM(4326).ST_ASWKT() AS HEXSHAPE\n",
    "FROM \n",
    "(\n",
    "    SELECT TOP 3 ST_CLUSTERCELL() AS HEXCELL\n",
    "    FROM TAXI\n",
    "    GROUP CLUSTER BY STARTPOINT USING HEXAGON X CELLS 500\n",
    "    ORDER BY COUNT(*) DESC\n",
    ") A LEFT JOIN OSM_POI B ON A.HEXCELL.ST_INTERSECTS(B.SHAPE) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_cells = sql_result.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_top_cells_config = {\n",
    "    'version': 'v1',\n",
    "    'config': {\n",
    "        'mapState': {\n",
    "           'latitude': 41.14581779896211,\n",
    "           'longitude': -8.598703907021486,\n",
    "           'zoom': 13.933597056454914\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "KeplerGl(height=500, data={'top_cells':df_top_cells}, config=map_top_cells_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick-up Locations Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch hex clusters over time. Only pick the ones having more than 1 occurence to make the visualization less noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql sql_result <<\n",
    "SELECT \n",
    "    CLUSTERID, \n",
    "    CLUSTERCELL.ST_TRANSFORM(4326).ST_ASGEOJSON() AS CLUSTERCELL, \n",
    "    HOURBIN,\n",
    "    LOG(10, COUNT(*)) AS QUANTITY\n",
    "FROM\n",
    "(\n",
    "    SELECT \n",
    "        TO_TIMESTAMP(YEAR(STARTTIME) || '-' || MONTH(STARTTIME) || '-' || DAYOFMONTH(STARTTIME) || ' ' || LPAD(HOUR(STARTTIME) - MOD(HOUR(STARTTIME),2), 2, '0') || ':00:00') AS HOURBIN,\n",
    "        ST_CLUSTERID() OVER (CLUSTER BY STARTPOINT USING HEXAGON X CELLS 250) AS CLUSTERID,\n",
    "        ST_CLUSTERCELL() OVER (CLUSTER BY STARTPOINT USING HEXAGON X CELLS 250) AS CLUSTERCELL,\n",
    "        TRIP_ID\n",
    "    FROM TAXI\n",
    ")\n",
    "GROUP BY CLUSTERID, CLUSTERCELL, HOURBIN\n",
    "HAVING COUNT(*) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickup_time = sql_result.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_pickup_time_config = {'version': 'v1',\n",
    " 'config': {'visState': {'filters': [{'dataId': 'timebins',\n",
    "     'id': '2clyivov',\n",
    "     'name': 'hourbin',\n",
    "     'type': 'timeRange',\n",
    "     'value': [1385856000000, 1385863200000],\n",
    "     'enlarged': True,\n",
    "     'plotType': 'histogram',\n",
    "     'yAxis': None}],\n",
    "   'layers': [{'id': 'nngj5g8j',\n",
    "     'type': 'geojson',\n",
    "     'config': {'dataId': 'timebins',\n",
    "      'label': 'timebins',\n",
    "      'color': [248, 149, 112],\n",
    "      'columns': {'geojson': 'clustercell'},\n",
    "      'isVisible': True,\n",
    "      'visConfig': {'opacity': 0.8,\n",
    "       'thickness': 0.5,\n",
    "       'strokeColor': [130, 154, 227],\n",
    "       'colorRange': {'name': 'Uber Viz Diverging 1.5',\n",
    "        'type': 'diverging',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#00939C',\n",
    "         '#5DBABF',\n",
    "         '#BAE1E2',\n",
    "         '#F8C0AA',\n",
    "         '#DD7755',\n",
    "         '#C22E00']},\n",
    "       'strokeColorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'radius': 10,\n",
    "       'sizeRange': [0, 10],\n",
    "       'radiusRange': [0, 50],\n",
    "       'heightRange': [0, 500],\n",
    "       'elevationScale': 5,\n",
    "       'stroked': True,\n",
    "       'filled': True,\n",
    "       'enable3d': True,\n",
    "       'wireframe': False},\n",
    "      'textLabel': [{'field': None,\n",
    "        'color': [255, 255, 255],\n",
    "        'size': 18,\n",
    "        'offset': [0, 0],\n",
    "        'anchor': 'start',\n",
    "        'alignment': 'center'}]},\n",
    "     'visualChannels': {'colorField': {'name': 'quantity', 'type': 'real'},\n",
    "      'colorScale': 'quantile',\n",
    "      'sizeField': None,\n",
    "      'sizeScale': 'linear',\n",
    "      'strokeColorField': None,\n",
    "      'strokeColorScale': 'quantile',\n",
    "      'heightField': {'name': 'quantity', 'type': 'real'},\n",
    "      'heightScale': 'linear',\n",
    "      'radiusField': None,\n",
    "      'radiusScale': 'linear'}}],\n",
    "   'interactionConfig': {'tooltip': {'fieldsToShow': {'timebins': ['clusterid',\n",
    "       'hourbin',\n",
    "       'numberbin',\n",
    "       'quantity']},\n",
    "     'enabled': True},\n",
    "    'brush': {'size': 0.5, 'enabled': False}},\n",
    "   'layerBlending': 'normal',\n",
    "   'splitMaps': [],\n",
    "   'animationConfig': {'currentTime': None, 'speed': 1}},\n",
    "  'mapState': {'bearing': 112.9908256880734,\n",
    "   'dragRotate': True,\n",
    "   'latitude': 41.20398275560239,\n",
    "   'longitude': -8.67967113104948,\n",
    "   'pitch': 52.77444039813042,\n",
    "   'zoom': 10.424667679276855,\n",
    "   'isSplit': False},\n",
    "  'mapStyle': {'styleType': 'dark',\n",
    "   'topLayerGroups': {},\n",
    "   'visibleLayerGroups': {'label': True,\n",
    "    'road': True,\n",
    "    'border': False,\n",
    "    'building': True,\n",
    "    'water': True,\n",
    "    'land': True,\n",
    "    '3d building': False},\n",
    "   'threeDBuildingColor': [9.665468314072013,\n",
    "    17.18305478057247,\n",
    "    31.1442867897876],\n",
    "   'mapStyles': {}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeplerGl(height=700, data={'timebins':df_pickup_time}, config=map_pickup_time_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Route to the Airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation between Start and Destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query and visualize all start/end combinations, which have been observed with more than 100 trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql sql_result <<\n",
    "SELECT \n",
    "        START_HEXID,\n",
    "        START_CENTROID.ST_TRANSFORM(4326).ST_X() AS START_CELL_LON,\n",
    "        START_CENTROID.ST_TRANSFORM(4326).ST_Y() AS START_CELL_LAT,\n",
    "        END_HEXID,\n",
    "        END_CENTROID.ST_TRANSFORM(4326).ST_X() AS END_CELL_LON,\n",
    "        END_CENTROID.ST_TRANSFORM(4326).ST_Y() AS END_CELL_LAT,\n",
    "        COUNT(*) AS CNT\n",
    "FROM \n",
    "(\n",
    "    SELECT \n",
    "        TRIP_ID, \n",
    "        a.HEXID AS START_HEXID,\n",
    "        a.HEXCENTROID AS START_CENTROID,\n",
    "        b.HEXID AS END_HEXID,\n",
    "        b.HEXCENTROID AS END_CENTROID\n",
    "    FROM TAXI\n",
    "    LEFT JOIN REFGRID a ON STARTPOINT.ST_WITHIN(a.HEXCELL) = 1\n",
    "    LEFT JOIN REFGRID b ON ENDPOINT.ST_WITHIN(b.HEXCELL) = 1\n",
    ")\n",
    "GROUP BY START_HEXID, START_CENTROID, END_HEXID, END_CENTROID\n",
    "HAVING COUNT(*) > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cell_relation = sql_result.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config_cell_relation = {'version': 'v1',\n",
    " 'config': {'visState': {'filters': [],\n",
    "   'layers': [{'id': 'j9i3lca',\n",
    "     'type': 'arc',\n",
    "     'config': {'dataId': 'cell relation',\n",
    "      'label': 'cell relation',\n",
    "      'color': [207, 237, 181],\n",
    "      'columns': {'lat0': 'start_cell_lat',\n",
    "       'lng0': 'start_cell_lon',\n",
    "       'lat1': 'end_cell_lat',\n",
    "       'lng1': 'end_cell_lon'},\n",
    "      'isVisible': True,\n",
    "      'visConfig': {'opacity': 0.8,\n",
    "       'thickness': 2,\n",
    "       'colorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'sizeRange': [0, 10],\n",
    "       'targetColor': [245, 153, 153]},\n",
    "      'textLabel': [{'field': None,\n",
    "        'color': [255, 255, 255],\n",
    "        'size': 18,\n",
    "        'offset': [0, 0],\n",
    "        'anchor': 'start',\n",
    "        'alignment': 'center'}]},\n",
    "     'visualChannels': {'colorField': None,\n",
    "      'colorScale': 'quantile',\n",
    "      'sizeField': {'name': 'cnt', 'type': 'integer'},\n",
    "      'sizeScale': 'linear'}}],\n",
    "   'interactionConfig': {'tooltip': {'fieldsToShow': {'cell relation': ['start_hexid',\n",
    "       'cnt',\n",
    "       'end_hexid']},\n",
    "     'enabled': True},\n",
    "    'brush': {'size': 0.5, 'enabled': False}},\n",
    "   'layerBlending': 'normal',\n",
    "   'splitMaps': [],\n",
    "   'animationConfig': {'currentTime': None, 'speed': 1}},\n",
    "  'mapState': {'bearing': 26.752293577981668,\n",
    "   'dragRotate': True,\n",
    "   'latitude': 41.1926903030073,\n",
    "   'longitude': -8.61496918743284,\n",
    "   'pitch': 57.99119946737215,\n",
    "   'zoom': 11.287843857109973,\n",
    "   'isSplit': False},\n",
    "  'mapStyle': {'styleType': 'light',\n",
    "   'topLayerGroups': {},\n",
    "   'visibleLayerGroups': {'label': True,\n",
    "    'road': True,\n",
    "    'border': False,\n",
    "    'building': True,\n",
    "    'water': True,\n",
    "    'land': True,\n",
    "    '3d building': False},\n",
    "   'threeDBuildingColor': [9.665468314072013,\n",
    "    17.18305478057247,\n",
    "    31.1442867897876],\n",
    "   'mapStyles': {}}}}\n",
    "\n",
    "KeplerGl(height=500, data={'cell relation':df_cell_relation}, config=config_cell_relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the visualization above we can anticipate that most trips to the airport start in the area around Sao Bento station."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is The Best Way From Sao Bento Station To The Airport?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query and visualize all trips from Sao Bento Station to the airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql sql_result <<\n",
    "SELECT\n",
    "    INDEX, \n",
    "    TRIP_ID, \n",
    "    CALL_TYPE, \n",
    "    TAXI_ID, \n",
    "    STARTTIME, \n",
    "    ENDTIME,\n",
    "    SPEED_AVG,\n",
    "    DURATION,\n",
    "    DISTANCE,\n",
    "    SHAPE.ST_TRANSFORM(4326).ST_ASWKT() as SHAPE,\n",
    "    a.HEXCELL.ST_TRANSFORM(4326).ST_ASWKT() AS START_HEXCELL,\n",
    "    b.HEXCELL.ST_TRANSFORM(4326).ST_ASWKT() AS END_HEXCELL\n",
    "FROM TAXI t\n",
    "LEFT JOIN REFGRID a ON STARTPOINT.ST_WITHIN(a.HEXCELL) = 1\n",
    "LEFT JOIN REFGRID b ON ENDPOINT.ST_WITHIN(b.HEXCELL) = 1\n",
    "WHERE a.HEXID = 'HEXID-86826' AND b.HEXID = 'HEXID-90071' AND DISTANCE < 2 * a.HEXCENTROID.ST_DISTANCE(b.HEXCENTROID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequent_route = sql_result.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config_frequent_route = {'version': 'v1',\n",
    " 'config': {'visState': {'filters': [],\n",
    "   'layers': [{'id': 'byb7s0c',\n",
    "     'type': 'geojson',\n",
    "     'config': {'dataId': 'frequent route',\n",
    "      'label': 'frequent route',\n",
    "      'color': [130, 154, 227],\n",
    "      'columns': {'geojson': 'shape'},\n",
    "      'isVisible': True,\n",
    "      'visConfig': {'opacity': 0.8,\n",
    "       'thickness': 0.5,\n",
    "       'strokeColor': None,\n",
    "       'colorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'strokeColorRange': {'name': 'Uber Viz Diverging 1.5',\n",
    "        'type': 'diverging',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#00939C',\n",
    "         '#5DBABF',\n",
    "         '#BAE1E2',\n",
    "         '#F8C0AA',\n",
    "         '#DD7755',\n",
    "         '#C22E00']},\n",
    "       'radius': 10,\n",
    "       'sizeRange': [0, 10],\n",
    "       'radiusRange': [0, 50],\n",
    "       'heightRange': [0, 500],\n",
    "       'elevationScale': 5,\n",
    "       'stroked': True,\n",
    "       'filled': False,\n",
    "       'enable3d': False,\n",
    "       'wireframe': False},\n",
    "      'textLabel': [{'field': None,\n",
    "        'color': [255, 255, 255],\n",
    "        'size': 18,\n",
    "        'offset': [0, 0],\n",
    "        'anchor': 'start',\n",
    "        'alignment': 'center'}]},\n",
    "     'visualChannels': {'colorField': None,\n",
    "      'colorScale': 'quantile',\n",
    "      'sizeField': None,\n",
    "      'sizeScale': 'linear',\n",
    "      'strokeColorField': {'name': 'duration', 'type': 'integer'},\n",
    "      'strokeColorScale': 'quantile',\n",
    "      'heightField': None,\n",
    "      'heightScale': 'linear',\n",
    "      'radiusField': None,\n",
    "      'radiusScale': 'linear'}},\n",
    "    {'id': '9phu6iq',\n",
    "     'type': 'geojson',\n",
    "     'config': {'dataId': 'frequent route',\n",
    "      'label': 'frequent route',\n",
    "      'color': [231, 159, 213],\n",
    "      'columns': {'geojson': 'start_hexcell'},\n",
    "      'isVisible': True,\n",
    "      'visConfig': {'opacity': 0.8,\n",
    "       'thickness': 0.5,\n",
    "       'strokeColor': [30, 150, 190],\n",
    "       'colorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'strokeColorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'radius': 10,\n",
    "       'sizeRange': [0, 10],\n",
    "       'radiusRange': [0, 50],\n",
    "       'heightRange': [0, 500],\n",
    "       'elevationScale': 5,\n",
    "       'stroked': True,\n",
    "       'filled': True,\n",
    "       'enable3d': False,\n",
    "       'wireframe': False},\n",
    "      'textLabel': [{'field': None,\n",
    "        'color': [255, 255, 255],\n",
    "        'size': 18,\n",
    "        'offset': [0, 0],\n",
    "        'anchor': 'start',\n",
    "        'alignment': 'center'}]},\n",
    "     'visualChannels': {'colorField': None,\n",
    "      'colorScale': 'quantile',\n",
    "      'sizeField': None,\n",
    "      'sizeScale': 'linear',\n",
    "      'strokeColorField': None,\n",
    "      'strokeColorScale': 'quantile',\n",
    "      'heightField': None,\n",
    "      'heightScale': 'linear',\n",
    "      'radiusField': None,\n",
    "      'radiusScale': 'linear'}},\n",
    "    {'id': 'e7hwsd',\n",
    "     'type': 'geojson',\n",
    "     'config': {'dataId': 'frequent route',\n",
    "      'label': 'frequent route',\n",
    "      'color': [137, 218, 193],\n",
    "      'columns': {'geojson': 'end_hexcell'},\n",
    "      'isVisible': True,\n",
    "      'visConfig': {'opacity': 0.8,\n",
    "       'thickness': 0.5,\n",
    "       'strokeColor': [179, 173, 158],\n",
    "       'colorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'strokeColorRange': {'name': 'Global Warming',\n",
    "        'type': 'sequential',\n",
    "        'category': 'Uber',\n",
    "        'colors': ['#5A1846',\n",
    "         '#900C3F',\n",
    "         '#C70039',\n",
    "         '#E3611C',\n",
    "         '#F1920E',\n",
    "         '#FFC300']},\n",
    "       'radius': 10,\n",
    "       'sizeRange': [0, 10],\n",
    "       'radiusRange': [0, 50],\n",
    "       'heightRange': [0, 500],\n",
    "       'elevationScale': 5,\n",
    "       'stroked': True,\n",
    "       'filled': True,\n",
    "       'enable3d': False,\n",
    "       'wireframe': False},\n",
    "      'textLabel': [{'field': None,\n",
    "        'color': [255, 255, 255],\n",
    "        'size': 18,\n",
    "        'offset': [0, 0],\n",
    "        'anchor': 'start',\n",
    "        'alignment': 'center'}]},\n",
    "     'visualChannels': {'colorField': None,\n",
    "      'colorScale': 'quantile',\n",
    "      'sizeField': None,\n",
    "      'sizeScale': 'linear',\n",
    "      'strokeColorField': None,\n",
    "      'strokeColorScale': 'quantile',\n",
    "      'heightField': None,\n",
    "      'heightScale': 'linear',\n",
    "      'radiusField': None,\n",
    "      'radiusScale': 'linear'}}],\n",
    "   'interactionConfig': {'tooltip': {'fieldsToShow': {'frequent route': ['index',\n",
    "       'trip_id',\n",
    "       'call_type',\n",
    "       'taxi_id',\n",
    "       'starttime']},\n",
    "     'enabled': True},\n",
    "    'brush': {'size': 0.5, 'enabled': False}},\n",
    "   'layerBlending': 'normal',\n",
    "   'splitMaps': [],\n",
    "   'animationConfig': {'currentTime': None, 'speed': 1}},\n",
    "  'mapState': {'bearing': 0,\n",
    "   'dragRotate': False,\n",
    "   'latitude': 41.190118850547385,\n",
    "   'longitude': -8.63244718721786,\n",
    "   'pitch': 0,\n",
    "   'zoom': 11.044961898535204,\n",
    "   'isSplit': False},\n",
    "  'mapStyle': {'styleType': 'dark',\n",
    "   'topLayerGroups': {},\n",
    "   'visibleLayerGroups': {'label': True,\n",
    "    'road': True,\n",
    "    'border': False,\n",
    "    'building': True,\n",
    "    'water': True,\n",
    "    'land': True,\n",
    "    '3d building': False},\n",
    "   'threeDBuildingColor': [9.665468314072013,\n",
    "    17.18305478057247,\n",
    "    31.1442867897876],\n",
    "   'mapStyles': {}}}}\n",
    "\n",
    "KeplerGl(height=500, data={'frequent route':df_frequent_route}, config=config_frequent_route)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HANA Embedded Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the hana_ml client for db communication. This way we can make sure, that the data resides in the database and gets processed by embedded ML. I.e. HANA ML DataFrame object will not have a persistence in Python unless 'collect()' gets called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml import dataframe\n",
    "from hana_ml.algorithms.apl import regression\n",
    "from matplotlib import pyplot\n",
    "from hana_ml.algorithms.apl import gradient_boosting_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-usable function for retrieving performance metrics as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics_df(model):\n",
    "    d = model.get_performance_metrics()\n",
    "    df = pd.DataFrame(list(d.items()), columns=[\"Metric\", \"Value\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-usable function for plotting feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model):\n",
    "    # retrieve importance as df\n",
    "    d = model.get_feature_importances()\n",
    "    df = pd.DataFrame(list(d.items()), columns=[\"Variable\", \"Contribution\"])\n",
    "    df['Contribution'] = df['Contribution'].astype(float)\n",
    "    df['Cumulative'] = df['Contribution'].cumsum()\n",
    "    df['Contribution'] = df['Contribution'].round(4)*100\n",
    "    df['Cumulative'] = df['Cumulative'].round(4)*100\n",
    "    non_zero = df['Contribution'] != 0\n",
    "    dfs = df[non_zero].sort_values(by=['Contribution'], ascending=False)\n",
    "    \n",
    "    # visualize importance as bar chart\n",
    "    c_title = \"Contributions\"\n",
    "    dfs = dfs.sort_values(by=['Contribution'], ascending=True)\n",
    "    dfs.plot(kind='barh', x='Variable', y='Contribution', title=c_title,legend=False, fontsize=12)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-usable function for plotting the group significance of a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_group_significance(model, feature):\n",
    "    df = model.get_indicators().filter(\"VARIABLE='\" + feature + \"' and KEY='GroupSignificance'\").collect()\n",
    "    df['VALUE'] = df['VALUE'].astype(float)\n",
    "    df.sort_values('VALUE', inplace = True, ascending = False)\n",
    "    \n",
    "    c_title = \"Significance\"\n",
    "    df.plot(kind='barh', x='DETAIL', y='VALUE', title=c_title,legend=False, fontsize=12)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = dataframe.ConnectionContext(hdb_host, hdb_port, hdb_user, hdb_password)\n",
    "conn.sql('SET SCHEMA %s' % (hdb_schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the duration of a trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_trajectories = conn.sql('''\n",
    "    SELECT\n",
    "        INDEX,\n",
    "        STARTTIME,\n",
    "        R1.HEXID AS HEXID_START,\n",
    "        R2.HEXID AS HEXID_END,\n",
    "        DURATION\n",
    "    FROM TAXI\n",
    "    LEFT JOIN REFGRID R1 ON STARTPOINT.ST_WITHIN(R1.HEXCELL) = 1\n",
    "    LEFT JOIN REFGRID R2 ON ENDPOINT.ST_WITHIN(R2.HEXCELL) = 1\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_model = regression.AutoRegressor(conn_context = conn, variable_auto_selection = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model or alternatively load model from HANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model:\n",
    "regr_model.fit(hdf_trajectories, label='DURATION', features=['STARTTIME', 'HEXID_START', 'HEXID_END'], key='INDEX')\n",
    "\n",
    "# Load pre-trained model:\n",
    "# regr_model.load_model(hdb_schema, 'MODEL_DURATION')\n",
    "# regr_model.indicators_ = conn.sql('SELECT * FROM MODEL_DURATION_INDICATORS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model in HANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_model.save_artifact(regr_model.indicators_, hdb_schema, 'MODEL_DURATION_INDICATORS', if_exists='replace')\n",
    "regr_model.save_model(hdb_schema, 'MODEL_DURATION', if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics_df(regr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(regr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the significance of a certain dimension (e.g. Hour of day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_group_significance(regr_model, 'STARTTIME_H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction for the trip to the airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_predict = conn.sql('''\n",
    "    SELECT\n",
    "        0 INDEX,\n",
    "        '2020-02-10 20:00:00' as STARTTIME,\n",
    "        'HEXID-86826' AS HEXID_START,\n",
    "        'HEXID-90071' AS HEXID_END\n",
    "    FROM DUMMY\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_model.predict(hdf_predict).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the feasibility yourself: https://www.google.com/maps/dir/S%C3%A3o+Bento+Station,+Pra%C3%A7a+de+Almeida+Garrett,+Porto,+Portugal/Francisco+S%C3%A1+Carneiro+Airport+(OPO),+Maia,+Portugal/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict where a taxi ride is going to end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a limitation of APL: A maximum of 100 target classes is allowed. Let's see what the influence on our analysis will be when only considering the 100 most frequent destinations in Porto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT SUM(NTRIPS) AS TOP100_LOC, 100 * SUM(NTRIPS) / (SELECT COUNT(*) FROM TAXI) AS PERCENTAGE\n",
    "FROM\n",
    "(\n",
    "    SELECT TOP 100 HEXID, COUNT(*) as NTRIPS\n",
    "    FROM TAXI\n",
    "    LEFT JOIN REFGRID ON ENDPOINT.ST_WITHIN(HEXCELL) = 1\n",
    "    GROUP BY HEXID\n",
    "    ORDER BY COUNT(*) DESC\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means, when only looking at the top 100 taxi destinations we actually cover almost all trips. I would argue that the remaining destinations actually have a so little number of trips, that the prediction would be unstable anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a compass to see in which direction the taxi was going after the first 5 coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ALTER TABLE TAXI ADD (COMPASS NVARCHAR(2))\n",
    "%sql ALTER TABLE TAXI ADD (COMPASS_DIST INTEGER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "UPDATE TAXI T SET \n",
    "    COMPASS = \n",
    "        CASE \n",
    "            WHEN 1 - ABS(D.DIR) <= 0.125 THEN 'W'\n",
    "            WHEN ABS(0 - D.DIR) <= 0.125 THEN 'E'\n",
    "            WHEN ABS(0.5 - D.DIR) <= 0.125 THEN 'N'\n",
    "            WHEN ABS(-0.5 - D.DIR) <= 0.125 THEN 'S'\n",
    "            WHEN ABS(0.25 - D.DIR) < 0.125 THEN 'NE'\n",
    "            WHEN ABS(0.75 - D.DIR) < 0.125 THEN 'NW'\n",
    "            WHEN ABS(-0.25 - D.DIR) < 0.125 THEN 'SE'\n",
    "            WHEN ABS(-0.75 - D.DIR) < 0.125 THEN 'SW'\n",
    "            ELSE NULL\n",
    "        END,\n",
    "    COMPASS_DIST = STARTPOINT.ST_DISTANCE(SHAPE.ST_POINTN(10))\n",
    "FROM\n",
    "    TAXI T,\n",
    "    (\n",
    "        SELECT TRIP_ID, 0.5 * atan2(SHAPE.ST_POINTN(10).ST_Y() - STARTPOINT.ST_Y(), SHAPE.ST_POINTN(10).ST_X() - STARTPOINT.ST_X())/acos(0) AS DIR\n",
    "        FROM TAXI\n",
    "        WHERE SHAPE.ST_NUMPOINTS() > 10\n",
    "    ) D\n",
    "WHERE T.TRIP_ID = D.TRIP_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of sample records to fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 75000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather training data and consider only rides having enought trajectory points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_rides = conn.sql('''\n",
    "    SELECT *, RANDOM_PARTITION(0.8, 0.0, 0.2, 0) OVER (ORDER BY STARTTIME) AS SET_NUM\n",
    "    FROM\n",
    "    (\n",
    "        SELECT TOP %s\n",
    "            TRIP_ID,\n",
    "            CALL_TYPE,\n",
    "            DAY_TYPE,\n",
    "            STARTTIME,\n",
    "            COMPASS,\n",
    "            COMPASS_DIST,\n",
    "            a.HEXID AS START_HEXID,\n",
    "            b.HEXID AS END_HEXID\n",
    "        FROM TAXI\n",
    "        LEFT JOIN REFGRID a ON STARTPOINT.ST_WITHIN(a.HEXCELL) = 1\n",
    "        LEFT JOIN REFGRID b ON ENDPOINT.ST_WITHIN(b.HEXCELL) = 1\n",
    "        WHERE \n",
    "            COMPASS IS NOT NULL\n",
    "        AND b.HEXID IN\n",
    "        (\n",
    "            SELECT TOP 100 HEXID\n",
    "            FROM TAXI\n",
    "            LEFT JOIN REFGRID ON ENDPOINT.ST_WITHIN(HEXCELL) = 1\n",
    "            GROUP BY HEXID\n",
    "            ORDER BY COUNT(*) DESC\n",
    "        )\n",
    "        ORDER BY RAND()\n",
    "    )\n",
    "''' % (n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_rides.head(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf_rides.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf_rides.filter('SET_NUM=1').count() #training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf_rides.filter('SET_NUM=3').count() #test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate multi-classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = gradient_boosting_classification.GradientBoostingClassifier(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model or alternatively load model from HANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model\n",
    "gb_model.fit(\n",
    "    hdf_rides.filter('SET_NUM=1'), \n",
    "    label='END_HEXID', \n",
    "    key = 'TRIP_ID',\n",
    "    features = ['CALL_TYPE', 'DAY_TYPE', 'STARTTIME', 'COMPASS', 'COMPASS_DIST', 'START_HEXID'])\n",
    "\n",
    "# Load pre-trained model:\n",
    "# gb_model.load_model(hdb_schema, 'MODEL_DESTINATION')\n",
    "# gb_model.indicators_ = conn.sql('SELECT * FROM MODEL_DESTINATION_INDICATORS')\n",
    "# gb_model.summary_ = conn.sql('SELECT * FROM MODEL_DESTINATION_SUMMARY')\n",
    "# gb_model.label = 'END_HEXID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model to HANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model.save_artifact(gb_model.indicators_, hdb_schema, 'MODEL_DESTINATION_INDICATORS', if_exists='replace')\n",
    "gb_model.save_artifact(gb_model.summary_, hdb_schema, 'MODEL_DESTINATION_SUMMARY', if_exists='replace')\n",
    "gb_model.save_model(hdb_schema, 'MODEL_DESTINATION', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics_df(gb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model.get_feature_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hdf_predict = gb_model.predict(hdf_rides.filter('SET_NUM=3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the geo information back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_predict_refgrid = hdf_predict.join(\n",
    "        conn.table('REFGRID'), \n",
    "        'TRUE_LABEL = HEXID', \n",
    "        select=[('TRIP_ID'), ('TRUE_LABEL'), ('PREDICTED'), ('PROBABILITY'), ('HEXCENTROID', 'TRUE_CENTROID')]\n",
    "    )\n",
    "hdf_predict_refgrid = hdf_predict_refgrid.join(\n",
    "        conn.table('REFGRID'), \n",
    "        'PREDICTED = HEXID', \n",
    "        select=[('TRIP_ID'), ('TRUE_LABEL'), ('PREDICTED'), ('PROBABILITY'), ('TRUE_CENTROID'), ('HEXCENTROID', 'PREDICTED_CENTROID')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_predict_refgrid.head(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate distance between predicted and true centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_predict_refgrid = hdf_predict_refgrid.select('*', ('TRUE_CENTROID.ST_DISTANCE(PREDICTED_CENTROID)', 'DIST'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate median distance of our predictions as a quality indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_predict_refgrid.agg([('AVG', 'DIST', 'AVG_DIST')]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set this into context, we need to know the size of our hexagons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT TOP 1 \n",
    "    HEXCELL.ST_EXTERIORRING().ST_POINTN(1).ST_DISTANCE(HEXCELL.ST_EXTERIORRING().ST_POINTN(4)) AS HEX_DIAMETER\n",
    "FROM REFGRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_prediction = hdf_predict_refgrid.filter('DIST < 1100').count()\n",
    "tp_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Nearly) correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%s%%' % (100 * tp_prediction / hdf_predict_refgrid.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark with a majority vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which cell is the most frequent destination?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_top_destination = conn.sql('''\n",
    "    SELECT TOP 1 HEXID, HEXCENTROID\n",
    "    FROM TAXI\n",
    "    LEFT JOIN REFGRID ON ENDPOINT.ST_WITHIN(HEXCELL) = 1\n",
    "    GROUP BY HEXID, HEXCENTROID\n",
    "    ORDER BY COUNT(*) DESC\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add frequent vote to prediction df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_predict_frequent = hdf_predict_refgrid.join(\n",
    "        hdf_top_destination, \n",
    "        \"1=1\", \n",
    "        select=[('TRIP_ID'), ('TRUE_LABEL'), ('PREDICTED'), ('PROBABILITY'), ('TRUE_CENTROID'), ('PREDICTED_CENTROID'), ('HEXCENTROID', 'FREQUENT_CENTROID')]\n",
    "    ).select(\n",
    "        '*', ('TRUE_CENTROID.ST_DISTANCE(FREQUENT_CENTROID)', 'FREQUENT_DIST')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_predict_frequent.agg([('AVG', 'FREQUENT_DIST', 'AVG_FREQUENT_DIST')]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_majority = hdf_predict_frequent.filter('FREQUENT_DIST < 1100').count()\n",
    "tp_majority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase in classification rate with model compared to majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%s%%' % (100 * (tp_prediction - tp_majority) / hdf_predict_refgrid.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
